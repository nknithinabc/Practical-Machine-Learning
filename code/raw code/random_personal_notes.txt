##Variables:

#

#Accel related:
	#total_accel_forearm
	#var_accel_forearm

#roll related:
	#roll_forearm
	#kurtosis_roll_forearm
	#skewness_roll_forearm
	#max_roll_forearm
	#min_roll_forearm
	#amplitude_roll_forearm
	#avg_roll_forearm
	#stddev_roll_forearm
	#var_roll_forearm

#Pitch related:
	#pitch_forearm
	#kurtosis_picth_forearm
	#skewness_pitch_forearm
	#max_picth_forearm
	#min_pitch_forearm
	#amplitude_pitch_forearm
	#avg_pitch_forearm
	#var_pitch_forearm
	#stddev_pitch_forearm

#yaw related:
	#yaw_forearm
	#kurtosis_yaw_forearm
	#skewness_yaw_forearm
	#max_yaw_forearm min_roll_forearm
	#min_yaw_forearm
	#amplitude_yaw_forearm
	#avg_yaw_forearm
	#stddev_yaw_forearm
	#var_yaw_forearm

#gyros_forearm (with measures on x,y,z axis)
#gyros_forearm (with measures on x,y,z axis)
#accel_forearm (with measures on x,y,z axis)
#magnet_forearm (with measures on x,y,z axis)

###Cleaning Data:
##DIV/0! appears in these variables: 
	#kurtosis_roll_belt, 
	#kurtosis_picth_belt, 
	#kurtosis_roll_forearm, 
	#kurtosis_yaw_belt
	#skewness_roll_belt
	#skewness_roll_belt.1
	#skewness_yaw_belt
	#




#NearZeroVariance Variables:
##vars:
#                           freqRatio percentUnique zeroVar   nzv
#new_window                 47.330049    0.01019264   FALSE  TRUE
#kurtosis_roll_belt       1921.600000    2.02323922   FALSE  TRUE
#kurtosis_picth_belt       600.500000    1.61553358   FALSE  TRUE
#kurtosis_yaw_belt          47.330049    0.01019264   FALSE  TRUE
#skewness_roll_belt       2135.111111    2.01304658   FALSE  TRUE
#skewness_roll_belt.1      600.500000    1.72255631   FALSE  TRUE
#skewness_yaw_belt          47.330049    0.01019264   FALSE  TRUE
#max_yaw_belt              640.533333    0.34654979   FALSE  TRUE
#min_yaw_belt              640.533333    0.34654979   FALSE  TRUE
#amplitude_yaw_belt         50.041667    0.02038528   FALSE  TRUE
#avg_roll_arm               77.000000    1.68178575   FALSE  TRUE
#stddev_roll_arm            77.000000    1.68178575   FALSE  TRUE
#var_roll_arm               77.000000    1.68178575   FALSE  TRUE
#avg_pitch_arm              77.000000    1.68178575   FALSE  TRUE
#stddev_pitch_arm           77.000000    1.68178575   FALSE  TRUE
#var_pitch_arm              77.000000    1.68178575   FALSE  TRUE
#avg_yaw_arm                77.000000    1.68178575   FALSE  TRUE
#stddev_yaw_arm             80.000000    1.66649679   FALSE  TRUE
#var_yaw_arm                80.000000    1.66649679   FALSE  TRUE
#kurtosis_roll_arm         246.358974    1.68178575   FALSE  TRUE
#kurtosis_picth_arm        240.200000    1.67159311   FALSE  TRUE
#kurtosis_yaw_arm         1746.909091    2.01304658   FALSE  TRUE
#skewness_roll_arm         249.558442    1.68688207   FALSE  TRUE
#skewness_pitch_arm        240.200000    1.67159311   FALSE  TRUE
#skewness_yaw_arm         1746.909091    2.01304658   FALSE  TRUE
#max_roll_arm               25.666667    1.47793293   FALSE  TRUE
#min_roll_arm               19.250000    1.41677709   FALSE  TRUE
#min_pitch_arm              19.250000    1.47793293   FALSE  TRUE
#amplitude_roll_arm         25.666667    1.55947406   FALSE  TRUE
#amplitude_pitch_arm        20.000000    1.49831821   FALSE  TRUE
#kurtosis_roll_dumbbell   3843.200000    2.02833554   FALSE  TRUE
#kurtosis_picth_dumbbell  9608.000000    2.04362450   FALSE  TRUE
#kurtosis_yaw_dumbbell      47.330049    0.01019264   FALSE  TRUE
#skewness_roll_dumbbell   4804.000000    2.04362450   FALSE  TRUE
#skewness_pitch_dumbbell  9608.000000    2.04872082   FALSE  TRUE
#skewness_yaw_dumbbell      47.330049    0.01019264   FALSE  TRUE
#max_yaw_dumbbell          960.800000    0.37203139   FALSE  TRUE
#min_yaw_dumbbell          960.800000    0.37203139   FALSE  TRUE
#amplitude_yaw_dumbbell     47.920200    0.01528896   FALSE  TRUE
#kurtosis_roll_forearm     228.761905    1.64101519   FALSE  TRUE
#kurtosis_picth_forearm    226.070588    1.64611151   FALSE  TRUE
#kurtosis_yaw_forearm       47.330049    0.01019264   FALSE  TRUE
#skewness_roll_forearm     231.518072    1.64611151   FALSE  TRUE
#skewness_pitch_forearm    226.070588    1.62572623   FALSE  TRUE
#skewness_yaw_forearm       47.330049    0.01019264   FALSE  TRUE
#max_roll_forearm           27.666667    1.38110284   FALSE  TRUE
#max_yaw_forearm           228.761905    0.22933442   FALSE  TRUE
#min_roll_forearm           27.666667    1.37091020   FALSE  TRUE
#min_yaw_forearm           228.761905    0.22933442   FALSE  TRUE
#amplitude_roll_forearm     20.750000    1.49322189   FALSE  TRUE
#amplitude_yaw_forearm      59.677019    0.01528896   FALSE  TRUE
#avg_roll_forearm           27.666667    1.64101519   FALSE  TRUE
#stddev_roll_forearm        87.000000    1.63082255   FALSE  TRUE
#var_roll_forearm           87.000000    1.63082255   FALSE  TRUE
#avg_pitch_forearm          83.000000    1.65120783   FALSE  TRUE
#stddev_pitch_forearm       41.500000    1.64611151   FALSE  TRUE
#var_pitch_forearm          83.000000    1.65120783   FALSE  TRUE
#avg_yaw_forearm            83.000000    1.65120783   FALSE  TRUE
#stddev_yaw_forearm         85.000000    1.64101519   FALSE  TRUE
#var_yaw_forearm            85.000000    1.64101519   FALSE  TRUE


##################
How to exclude Columns from a dataset:
# exclude variables v1, v2, v3
myvars <- names(mydata) %in% c("v1", "v2", "v3") 
newdata <- mydata[!myvars]

# exclude 3rd and 5th variable 
newdata <- mydata[c(-3,-5)]

# delete variables v3 and v5
mydata$v3 <- mydata$v5 <- NULL

#Source: http://www.statmethods.net/management/subset.html

##################

##################

Printouts from ML algorithms used:

> modFitA1 <- train(classe ~ ., method="rpart", data=trainingV2)
> print(modFitA1$finalModel)
n= 242 

node), split, n, loss, yval, (yprob)
      * denotes terminal node

1) root 242 167 A (0.31 0.17 0.17 0.14 0.21)  
  2) stddev_roll_belt< 1.35 195 121 A (0.38 0.21 0.22 0.13 0.067)  
    4) var_accel_dumbbell< 3.16975 155  87 A (0.44 0.09 0.26 0.16 0.052) *
    5) var_accel_dumbbell>=3.16975 40  14 B (0.15 0.65 0.05 0.025 0.12) *
  3) stddev_roll_belt>=1.35 47   9 E (0.021 0 0 0.17 0.81) *


#Now with rpart package

print(modFitA1)
n= 11776 

node), split, n, loss, yval, (yprob)
      * denotes terminal node

 1) root 11776 8428 A (0.28 0.19 0.17 0.16 0.18)  
   2) cvtd_timestamp=02/12/2011 13:32,02/12/2011 13:33,02/12/2011 13:34,02/12/2011 14:56,02/12/2011 14:57,05/12/2011 11:23,05/12/2011 11:24,05/12/2011 14:22,05/12/2011 14:23,28/11/2011 14:13,28/11/2011 14:14,30/11/2011 17:10,30/11/2011 17:11 7458 4110 A (0.45 0.3 0.2 0.046 0)  
     4) cvtd_timestamp=02/12/2011 13:32,02/12/2011 13:33,02/12/2011 14:56,05/12/2011 11:23,05/12/2011 14:22,28/11/2011 14:13,30/11/2011 17:10 2319  194 A (0.92 0.084 0 0 0)  
       8) raw_timestamp_part_1< 1.322833e+09 1725    0 A (1 0 0 0 0) *
       9) raw_timestamp_part_1>=1.322833e+09 594  194 A (0.67 0.33 0 0 0)  
        18) cvtd_timestamp=02/12/2011 14:56,05/12/2011 11:23,05/12/2011 14:22 394    0 A (1 0 0 0 0) *
        19) cvtd_timestamp=02/12/2011 13:33 200    6 B (0.03 0.97 0 0 0) *
     5) cvtd_timestamp=02/12/2011 13:34,02/12/2011 14:57,05/12/2011 11:24,05/12/2011 14:23,28/11/2011 14:14,30/11/2011 17:11 5139 3072 B (0.24 0.4 0.29 0.066 0)  
      10) magnet_dumbbell_z< -1.5 2580 1386 A (0.46 0.42 0.12 0.0019 0)  
        20) raw_timestamp_part_1< 1.323095e+09 2295 1101 A (0.52 0.47 0.0092 0.0022 0)  
          40) magnet_dumbbell_x< -460.5 1192  259 A (0.78 0.2 0.011 0.0042 0)  
            80) raw_timestamp_part_1< 1.323084e+09 1035  102 A (0.9 0.083 0.011 0.0048 0) *
            81) raw_timestamp_part_1>=1.323084e+09 157    2 B (0 0.99 0.013 0 0) *
          41) magnet_dumbbell_x>=-460.5 1103  269 B (0.24 0.76 0.0073 0 0)  
            82) num_window< 68.5 176    0 A (1 0 0 0 0) *
            83) num_window>=68.5 927   93 B (0.092 0.9 0.0086 0 0) *
        21) raw_timestamp_part_1>=1.323095e+09 285    0 C (0 0 1 0 0) *
      11) magnet_dumbbell_z>=-1.5 2559 1357 C (0.011 0.39 0.47 0.13 0)  
        22) magnet_dumbbell_x>=-484.5 908  238 B (0.013 0.74 0.15 0.097 0) *
        23) magnet_dumbbell_x< -484.5 1651  587 C (0.01 0.2 0.64 0.15 0)  
          46) pitch_belt< -43.25 147   21 B (0 0.86 0.14 0 0) *
          47) pitch_belt>=-43.25 1504  461 C (0.011 0.13 0.69 0.16 0) *
   3) cvtd_timestamp=02/12/2011 13:35,02/12/2011 14:58,02/12/2011 14:59,05/12/2011 11:25,05/12/2011 14:24,28/11/2011 14:15,30/11/2011 17:12 4318 2153 E (0 0.0042 0.13 0.37 0.5)  
     6) roll_belt< 125.5 3225 1648 D (0 0.0056 0.17 0.49 0.34)  
      12) roll_dumbbell< -66.03302 663  147 C (0 0.0075 0.78 0.087 0.13) *
      13) roll_dumbbell>=-66.03302 2562 1043 D (0 0.0051 0.012 0.59 0.39)  
        26) accel_forearm_x< -89.5 1524  291 D (0 0.0085 0.0085 0.81 0.17)  
          52) magnet_belt_y>=578.5 1347  140 D (0 0.0097 0.0097 0.9 0.085) *
          53) magnet_belt_y< 578.5 177   26 E (0 0 0 0.15 0.85) *
        27) accel_forearm_x>=-89.5 1038  303 E (0 0 0.016 0.28 0.71)  
          54) accel_dumbbell_y< 48.5 405  166 D (0 0 0.042 0.59 0.37) *
          55) accel_dumbbell_y>=48.5 633   47 E (0 0 0 0.074 0.93) *
     7) roll_belt>=125.5 1093   12 E (0 0 0 0.011 0.99) *


confusionMatrix(predictionsA, testingV3$classe)
Confusion Matrix and Statistics

          Reference
Prediction    A    B    C    D    E
         A 2131   61    8    1    0
         B   77 1310  147   77    0
         C   24  137 1185  180   56
         D    0   10   28  970  169
         E    0    0    0   58 1217

Overall Statistics
                                          
               Accuracy : 0.8683          
                 95% CI : (0.8607, 0.8757)
    No Information Rate : 0.2845          
    P-Value [Acc > NIR] : < 2.2e-16       
                                          
                  Kappa : 0.8335          
 Mcnemar's Test P-Value : NA              

Statistics by Class:

                     Class: A Class: B Class: C Class: D Class: E
Sensitivity            0.9547   0.8630   0.8662   0.7543   0.8440
Specificity            0.9875   0.9524   0.9387   0.9684   0.9909
Pos Pred Value         0.9682   0.8132   0.7491   0.8241   0.9545
Neg Pred Value         0.9821   0.9666   0.9708   0.9526   0.9658
Prevalence             0.2845   0.1935   0.1744   0.1639   0.1838
Detection Rate         0.2716   0.1670   0.1510   0.1236   0.1551
Detection Prevalence   0.2805   0.2053   0.2016   0.1500   0.1625
Balanced Accuracy      0.9711   0.9077   0.9025   0.8614   0.9175





#Random Forests

confusionMatrix(predictionsB1, testingV3$classe)
Confusion Matrix and Statistics

          Reference
Prediction    A    B    C    D    E
         A 2231    0    0    0    0
         B    1 1518    3    0    0
         C    0    0 1365    1    0
         D    0    0    0 1282    0
         E    0    0    0    3 1442

Overall Statistics
                                         
               Accuracy : 0.999          
                 95% CI : (0.998, 0.9996)
    No Information Rate : 0.2845         
    P-Value [Acc > NIR] : < 2.2e-16      
                                         
                  Kappa : 0.9987         
 Mcnemar's Test P-Value : NA             

Statistics by Class:

                     Class: A Class: B Class: C Class: D Class: E
Sensitivity            0.9996   1.0000   0.9978   0.9969   1.0000
Specificity            1.0000   0.9994   0.9998   1.0000   0.9995
Pos Pred Value         1.0000   0.9974   0.9993   1.0000   0.9979
Neg Pred Value         0.9998   1.0000   0.9995   0.9994   1.0000
Prevalence             0.2845   0.1935   0.1744   0.1639   0.1838
Detection Rate         0.2843   0.1935   0.1740   0.1634   0.1838
Detection Prevalence   0.2843   0.1940   0.1741   0.1634   0.1842
Balanced Accuracy      0.9998   0.9997   0.9988   0.9984   0.9998


##################







##################
The following code was not used:
#Trying to do some Exploratory Analysis around 
featurePlot(x=myData[, c("var1", "var2", "var3")], y=myData$classe, plot="pairs")

qplot(var1, var2, colour=classe, data=training)

qq <- qplot(var1, var2, colour=classe, data=training)
qq + geom_smooth(method="lm", formula=y~x)

##################


##################

More unused code:


####Experimenting partitioning the data:
#Method 1:
inTrain <- createDataPartition(y=myData$something, p=0.75, list=FALSE)
training <- myData[inTrain, ]; test <- myData[-inTrain, ]
dim(training); dim(test)

#Method 2: K-folds for Cross Validation approach
set.seed(12345)
#Devides training set into 4
folds <- createFolds(y=myData$typeVar, k=4, list=TRUE, returnTrain=TRUE)
sapply(folds, length)
fold1 <- folds[[1]]
fold2 <- folds[[2]]
fold3 <- folds[[3]]
fold4 <- folds[[4]]

#With Resampling (bootstrapping):
set.seed(12345)
folds <- createResample(y=myData$typeVar, times=4, list=TRUE)
sapply(folds, length)

#Note for the test Set:
folds <- createFolds(y=myData$typeVar, k=4, list=TRUE, returnTrain=FALSE)

##################





